{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from notebook import *\n",
    "# if get something about NUMEXPR_MAX_THREADS being set incorrectly, don't worry.  It's not a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cs203.is_response": true,
    "deletable": false,
    "editable": true,
    "tags": []
   },
   "source": [
    "<div class=\"namebox\">    \n",
    "Double Click to edit and enter your\n",
    "\n",
    "1.  Name\n",
    "2.  Student ID\n",
    "3.  @ucr.edu email address\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "<div style=\" font-size: 300% !important;\n",
    "    margin-top: 1.5em;\n",
    "    margin-bottom: 10px;\n",
    "    font-weight: bold;\n",
    "    line-height: 1.0;\n",
    "    text-align:center;\">\n",
    "Programming Assignment 3: Join -- the parallelism\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "In this assignment, you'll learn about the concepts of:\n",
    "\n",
    "1. Thread-level parallelism\n",
    "2. Multi-threading programming\n",
    "\n",
    "You are strongly encouraged to go through the following documents before starting.\n",
    "1.  The x86-64 assembly http://www.cs.cmu.edu/~fp/courses/15213-s06/misc/asm64-handout.pdf\n",
    "2.  Intel Alder Lake CPU Architectures https://ieeexplore.ieee.org/document/9747991\n",
    "This assignment includes a programming assignment. \n",
    "\n",
    "Check the course schedule for due date(s).\n",
    "\n",
    "We need to thank [Dr. Steven Swanson](https://cseweb.ucsd.edu/~swanson/) as a significant part of the assignment is orginated from Dr. Swanson's teaching materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "Your programming assignment in this assignment is an extension of your work on the assignment 5.  This time, you'll be parallelizing your implementation of matrix exponentiation.  You can use C++ threads, pthreads, or OpenMP.  The assignment assume you'll use OpenMP.  If you use one of the others, the course staff will be less able to help you out.\n",
    "\n",
    "You are free to use your (and only your) solution to the previous assignment as a starting point for this assignment.\n",
    "\n",
    "Most of this section is a verbatim copy of the PA for assignment 3.  The sections with new content have \"(New for Assignment 5)\" at the end of their names.\n",
    "\n",
    "Obviously, the performance targets have been increased.  Roughly speaking, the targets have increased to 2.5x (4x on Gradescope servers)!!!  There are four cores on our machine, and from what we have learned, it's very conservative to expect that speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "## Performance Variability (New for Programming Assignment 3)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**Multithreaded Performance is Variable**:  Multithreading introduces variability in performance.  You will only get credit for performance numbers recorded on gradescope, you may need to run your gradescope job more than once to get meaningful measurements.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Running code on multiple processors introduce performance variability -- some times up to 20% or more.  In the real world, you'd either tolerate this or spend a lot of time trying to fix it.  Neither of those works well in a assignment, because we have limited time and you need a grade that reflects the quality of your work rather than whether a run was lucky or unlucky.\n",
    "\n",
    "To address this problem, the assignment includes does two things:\n",
    "1.  It runs your code 10 times and takes the average.  This is implemented in the `Makefile`.\n",
    "2.  It includes a \"canary\" program with known performance.  \n",
    "\n",
    "The canary runs before your code and if the performance of the canary is too low, the autograder will reject the run.  This means that it is much more likely that your gradescope submissions will fail and you may need to submit several times to get a good measurement. \n",
    "\n",
    "With the canary filtering out slow runs, performance variation is less this 5%.  So there is some marginal value in submitting multiple times in the hopes of getting a slightly good score.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**Budget time for multiple submissions**:  Having to resubmit to gradscope due to canary failure is totally predictable, and you have been warned.  Plan to submit (and resubmit as necessary) well-ahead of the deadline. \n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "## Reference Code (New for Programming Assignment 3)\n",
    "\n",
    "The reference implementation is in `join_reference.hpp`.  It's basically the same as for Assignment 3 and implements the following SQL query.\n",
    "\n",
    "\n",
    "``SELECT SUM(orders.quantity * products.price) AS value FROM orders INNER JOIN products WHERE ON orders.product_id = products.product_id GROUP BY products.brand;``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_code(\"join_reference.hpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "Read through the code and comments to make sure you understand what the code is doing. \n",
    "\n",
    "## Detailed Requirements\n",
    "\n",
    "The requirements for the assignment are pretty simple:\n",
    "\n",
    "1. Values in ``orders`` and ``products`` can be any `int64_t` value.\n",
    "2. Records in ``orders`` and ``products`` are sorted. You should read `join_main.cpp` carefully to know how are data sorted.\n",
    "3. Your output must match the output of the code in `join_reference.hpp`.\n",
    "4. Your implementation should go in `join_solution.hpp`.  The starter version is just a copy of `join_reference.hpp`.\n",
    "5. Your implementation must generate exact the same result as `join_reference` function.\n",
    "6. Your implementation must achieve at least 4 $\\times$ speedup  on gradescope to score. The performance number you got in the datahub cluster does not count toward your final score for the programming assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Running the Code\n",
    "\n",
    "The driver code for the assignment is in `join_main.cpp` and `join.cpp`.  `join_main.cpp` is mostly command line processing (take a look if you want).  `join.cpp` is what actually calls your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_code(\"join.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It defines two functions:\n",
    "\n",
    "* `join_reference_c` implements the reference/baseline join/aggregation for the given SQL.\n",
    "* `join_solution_c` calls your code.\n",
    "\n",
    "To invoke these, you can build and run `join.exe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm join.exe; rm -f build/join*; make join.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "`join.exe` takes several command line parameters:\n",
    "\n",
    "The notable ones are:\n",
    "\n",
    "1. `-customers` -- number of total customers.\n",
    "2. `-products` -- number of total products.\n",
    "3. `-brands` -- number of total brands.\n",
    "4. `-i` sets the number of iterations.\n",
    "5. `-f` what functions to run.\n",
    "6. `-o` sets where statistics should go.\n",
    "7. `-v` compares the result with the reference solution.\n",
    "\n",
    "The first three of these can take multiple values and `join.exe` will run all combinations and they will end up in `stats.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cs203 run \"./join.exe -M 3300 -o stats.csv -v -t 1 4 8 -i 1 -customers 4096 -products 256 -brands 256 -f join_reference_c join_solution_c\"\n",
    "df =render_csv(\"stats.csv\")\n",
    "display_mono(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## OpenMP (New For Programming Assignment 3)\n",
    "\n",
    "OpenMP is automatically turned for your code in this assignment, so the `#pragma` command we used for the histogram should work fine.\n",
    "\n",
    "If you want to compile at the command line, you'll need to either do \n",
    "\n",
    "```\n",
    "export OPENMP=yes\n",
    "```\n",
    "\n",
    "once each time you log in or invoke `make` like so:\n",
    "\n",
    "```\n",
    "make join.exe OPENMP=yes\n",
    "```\n",
    "each time you build.\n",
    "\n",
    "### Key Commands\n",
    "\n",
    "The three `#pragma`s you'll need for this assignment are \n",
    "\n",
    "1. `#pragma omp parallel for` for parallelizing loops.\n",
    "2. `#pragma omp critical` for parallelizing loops.\n",
    "3. `#pragma omp simd` for vectorizing loops\n",
    "\n",
    "These are the only three used in the solution used to set the performance targets.\n",
    "\n",
    "These three blog posts provide a good introduction to these commands:\n",
    "\n",
    "* http://jakascorner.com/blog/2016/04/omp-introduction.html  \n",
    "* http://jakascorner.com/blog/2016/05/omp-for.html\n",
    "* http://jakascorner.com/blog/2016/07/omp-critical.html\n",
    "\n",
    "They are required reading.\n",
    "\n",
    "These articles provide some more advanced topics that might be useful:\n",
    "\n",
    "* http://jakascorner.com/blog/2016/06/omp-for-scheduling.html\n",
    "* http://jakascorner.com/blog/2016/06/omp-data-sharing-attributes.html\n",
    "* http://jakascorner.com/blog/2016/07/omp-default-none-and-const.html\n",
    "\n",
    "There's an enormous amount of bad information online about OpenMP.\n",
    "\n",
    "### Looking at OpenMP Assembly\n",
    "\n",
    "If you look at the assembly for OpenMP programs, you'll find that your loop body has been replaced with a function call.  OpenMP does this so it can tell it's worker threads to call the function to perform one iteration of your loop.\n",
    "\n",
    "### Caveats for our Tools\n",
    "\n",
    "First, `gprof` doesn't work on with multi-threaded programs.  You can use it for single-threaded runs, though.\n",
    "\n",
    "Second, Moneta's cache model is not multithread-aware, so the cache hit/miss numbers for multithreaded programs are not meaningful.\n",
    "\n",
    "Moneta may also show more threads that you might be expecting.  OpenMP threads seem to be Thread 0 and 13 and above.  If you see some threads that don't seem to be doing anything, that's not surprising or concerning.\n",
    "\n",
    "Finally, our performance counting code only collects data for one thread.  For OpenMP code this is ok:  all the threads do basically the same thing.  But you'll notice, for instance, that if a loop runs in 4 threads, the measure instruction count will go down by ~1/4 (assuming multi-threading didn't add a lot of overhead).\n",
    " \n",
    " \n",
    "### Controlling the Number of Threads\n",
    "\n",
    "By default the autograder will run your code with 12 threads.  If you want to use a different number in your final run, you can call \n",
    "\n",
    "```\t\t\t\n",
    "omp_set_num_threads(thread_count);\n",
    "```\n",
    "\n",
    "in your function. You should call it before the first OpenMP `#pragma`.\n",
    "\n",
    "I can control thread count during development with `-t`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Things To Try\n",
    "\n",
    "### Non-Deterministic Tests (New for Programming Assignment 3)\n",
    "\n",
    "With threading, comes non-deterministic bugs.  This means that the tests may fail only occasionally for your code.  If this seems to be happening, a good strategy is to just run them repeatedly and confirm that it's the case.\n",
    "\n",
    "It's not a bug in the benchmark, you have a thread synchronization error.\n",
    "\n",
    "\n",
    "### General Tips (New for Programming Assignment 3)\n",
    "\n",
    "In the examples we saw that loop tiling and OpenMP pragmas can work well together.  This carries through to how you should figure out what to parallelize.  It's worth your time to try parallelizing different loops and changing how your loops are nested to accommodate that.\n",
    "\n",
    "A few tips:\n",
    "\n",
    "1.  Use `ET` to guide your optimizations.\n",
    "1.  At this points you have many tools avaiassignmentle to you -- `omp parallel for`, `omp simd`, compiler optimizations, tiling.  The number of combinations is enormous.   I suggest applying them in this order (from largest impact-per-effort to smallest):\n",
    "    1.  Get last assignment into good shape (see notes above and slides from class)\n",
    "    2.  `omp parallel for`\n",
    "    3.  `omp simd`\n",
    "    4.  Fiddling with other compiler options/per-function compiler options.\n",
    "    5.  Crazy stuff like intrinsics for better SIMD performance.\n",
    "1.  While tiling only applied to loops with reuse (because temporal locality requires reuse), `parallel for` can apply to loops without reuse.  Same for `omp simd`.\n",
    "2.  `omp parallel for` implicitly does tiling, since it divides the iterations of the parallel loop across several cores.\n",
    "1.  Nesting parallel for loops with OpenMP is not usually a good idea (although it should work).  Start by picking one loop to parallelize.\n",
    "2.  You want to parallelize an outer loop, so that the threads are working on large pieces of computation and need to synchronize less.\n",
    "3.  Pay close attention to whether iterations of your parallel loop are writing to the same locations.  If so, you'll need a `omp critical` to ensure correct updates.\n",
    "\n",
    "This last point can be tricky.  If I have this code:\n",
    "\n",
    "```\n",
    "#pragma omp parallel for\n",
    "for(int i = 0; i < 10; i++) {\n",
    "    for(int j = 0; j < 10; j++) {\n",
    "        for(int k = 0; k < 10; k++) {\n",
    "            X[i][j] += Y[k][j];\n",
    "```\n",
    "\n",
    "The only store is the assignment to `X(i, j)`.  Since `i` is the index of the parallel loop, I know that no other thread will be updating `X(i,j)`, since no other thread will have the same value of `i`.\n",
    "\n",
    "However, in this code:\n",
    "\n",
    "```\n",
    "#pragma omp parallel for\n",
    "for(int i = 0; i < 10; i++) {\n",
    "    for(int j = 0; j < 10; j++) {\n",
    "        for(int k = 0; k < 10; k++) {\n",
    "            X[k][j] += Y[i][j];\n",
    "```\n",
    "\n",
    "I don't have the same guarantee.  Since `i` does is not used to select an element in `X`, every other thread will write to that location as well.  In that case, I could do\n",
    "\n",
    "```\n",
    "#pragma omp parallel for\n",
    "for(int i = 0; i < 10; i++) {\n",
    "    for(int j = 0; j < 10; j++) {\n",
    "        for(int k = 0; k < 10; k++) {\n",
    "#pragma omp critical\n",
    "            X[k][j] += Y[i][j];\n",
    "```\n",
    "Which will probably be really slow, or I could create a private tensor, do my updates there, and then merge them into `X`.\n",
    "\n",
    "5.  Pay close attention to write sharing when you are deciding how to parallelize.  Can the iterations of your parallel loop iterations write to the same place?\n",
    "4.  `omp simd` only works on inner loops.\n",
    "5.  `omp parallel for` works best on outer loops.\n",
    "7.  `gprof` doesn't work for multithreading, so use `ET` to measure how long things take.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Useful C++ ( Partly New For Programming Assignment 3) \n",
    "\n",
    "\n",
    "#### Controlling Compiler Optimizations\n",
    "\n",
    "First, you can prevent inlining of a particular function by declaring it like so:\n",
    "\n",
    "```\n",
    "void __attribute__((noinline)) join_solution(...)\n",
    "```\n",
    "\n",
    "This can make it easier to debug, because you can set a breakpoint on the function and it'll work like you expect.\n",
    "\n",
    "Second, you can turn on arbitrary optimizations for particular functions like so:\n",
    "\n",
    "```\n",
    "#pragma GCC push_options\n",
    "#pragma GCC optimize (\"unroll-loops\")\n",
    "\n",
    "void your_function() {\n",
    "}\n",
    "\n",
    "#pragma GCC pop_options\n",
    "```\n",
    "\n",
    "\n",
    "#### Assertions\n",
    "\n",
    "The `assert()` macro is useful tool for debugging and to avoid silly errors.\n",
    "\n",
    "If you say\n",
    "\n",
    "```\n",
    "assert(a > b);\n",
    "```\n",
    "\n",
    "And the expression is not true at run time, the assert with \"fail\" your program will crash with a somewhat useful error message.\n",
    "\n",
    "This is a useful way to document and enforce assumptions you make in your code.  For instance, I used an assert in `convolution_tiled_split()` to ensure that the tile size was > 8.\n",
    "\n",
    "You can get access to  `assert()` with \n",
    "\n",
    "```\n",
    "#include<cassert>\n",
    "```\n",
    "\n",
    "The overhead of asserts is low, but not zero.  I would not put any in one of your performance-critical loops.\n",
    "\n",
    "If you want to include asserts in performance-critical areas, you can add `-DNDEBUG` to the optimizations in `config.make`.  It'll disable all the `assert()`s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Do Your Work Here\n",
    "\n",
    "Below are the key commands you'll need to make progress on the assignment.\n",
    "\n",
    "### Setting Optimization Flags\n",
    "\n",
    "As in your last assignment, you can set optimization flags in `config.make`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_code(\"config.make\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Compiling and Running\n",
    "\n",
    "You can compile and the benchmarks locally using this command.  This is only useful for debugging.  Performance running locally is not very meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!make join.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the benchmark in the cloud and compare your performance with the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!make clean;make join.exe\n",
    "!cs203 run './join.exe -M 3300 -i 1 -threads 1 4 8 -customers 1024 2048 -products 1024 2048 -brands 64 -f join_reference_c join_solution_c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df =render_csv(\"stats.csv\")\n",
    "display_mono(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Final Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Running the cell does just what the Gradescope autograder does.  And the cell below shows the name and target speedups for each benchmark.  This takes 1-2 minutes to run.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**Only Gradescope Counts** The scores produced here **do not** count.  Only gradescope counts.  The results here should match what Gradescope does, but I would test your solution on Gradescope well-ahead of the deadline to ensure your code is working like you expect.\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**The autograder doesn't pass additional parameters**. You'll need to set up the optimal configurations your code in the best way possible.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -f build/join*\n",
    "!cs203 run \"make autograde\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "And run the autograder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p autograde; cp bench.csv autograde; cp correctness.csv autograde\n",
    "!./autograde.py --submission autograde --results autograde.json\n",
    "from autograde import compute_all_scores\n",
    "df = compute_all_scores(dir=\"autograde\")\n",
    "display_mono(df)\n",
    "print(f\"total points (performance): {round(sum(df['capped_score']), 2)}\")\n",
    "display_mono(render_csv(\"correctness.csv\"))\n",
    "corrects = compute_correctness(dir=\"autograde\")\n",
    "print(f\"correctness points: {corrects/4*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "The \"capped_score\" column contains the number of points you'll receive.\n",
    "\n",
    "And see the autograder's output like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_code(\"autograde.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Most of it is internal stuff that gradscope needs, but the key parts are the `score`, `max_score`, and `output` fields.\n",
    "\n",
    "All that's left is commit your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git commit -am \"Solution to the assignment.\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "If `git push` asks for your username, you'll need to push from the command line.\n",
    "\n",
    "If `git commit` tells you have uncommitted files, that's not a problem. \n",
    "\n",
    "If `git commit` tell you something like:\n",
    "\n",
    "```\n",
    "*** Please tell me who you are.\n",
    "\n",
    "Run\n",
    "\n",
    "git config --global user.email \"you@example.com\"\n",
    "git config --global user.name \"Your Name\"\n",
    "\n",
    "to set your account's default identity.\n",
    "Omit --global to set the identity only in this repository.\n",
    "\n",
    "fatal: unable to auto-detect email address (got 'prcheng@dsmlp-jupyter-prcheng.(none)')\n",
    "Warning: Permanently added the RSA host key for IP address '140.82.112.3' to the list of known hosts.\n",
    "Everything up-to-date\n",
    "```\n",
    "\n",
    "Then you can do (but fill in your @ucr.edu email and your name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cs203.is_response": true,
    "deletable": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"you@example.com\"\n",
    "!git config --global user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "source": [
    "This assignment completes our tour of exploiting modern processor (multi-threaded processors) features.  It explored what's required to exploit thread-level parallelism. It shows examples achieving better TLPs is really difficult -- coherency, consistency, locks ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "source": [
    "# Turning in the programming assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "\n",
    "You need to turn in your notebook and your programming assignment in the specific gradescope item.  \n",
    "After you complete the assignment, you will turn it in by submitting your latest github repository.\n",
    "\n",
    "**Step 1:**  Save your workbook!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!for i in 1 2 3 4 5; do echo Save your files!!; sleep 1; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Step 2:**  Commit everything. Please run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git commit -am \"Yay! I am ready to turn in!\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Step 3**: \n",
    "Submit through gradescope\n",
    "You'll turn in your programming assignment by providing gradescope with your github repo of this assignment.   It'll run the autograder and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "335px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
